import itertools
# Sort reads for rRNA ##########################################################

# import modules ###############################################################

# functions ####################################################################

def separate_fastq_to_fasta(file, file_outf, file_outr):
    def grouper(iterable, n, fillvalue=None):
        args = [iter(iterable)] * n
        return itertools.zip_longest(*args, fillvalue=fillvalue)
    def to_fasta(read):
        id = read[0]
        id = id[1:]
        id = ">"+id.split()[1]
        seq = read[1]
        yield id+"\n"+seq
    with open(file_outf, "w") as g:
        with open(file_outr, "w") as h:
            with open(file) as f:
                for lines in grouper(f, 8, ''):
                    read_f = lines[0:4]
                    read_r = lines[4:8]
                    for res in to_fasta(read_f):
                        g.write(res)
                    for res in to_fasta(read_r):
                        h.write(res)

def separate_fastq(file, file_outf, file_outr):
    def grouper(iterable, n, fillvalue=None):
        args = [iter(iterable)] * n
        return itertools.zip_longest(*args, fillvalue=fillvalue)
    with open(file_outf, "w") as g:
        with open(file_outr, "w") as h:
            with open(file) as f:
                for lines in grouper(f, 8, ''):
                    read_f = lines[0:4]
                    read_r = lines[4:8]
                    for res in read_f:
                        g.write(res)
                    for res in read_r:
                        h.write(res)

# include subworkflows ## ######################################################

# subworkflow to create sortmerna database
subworkflow sortmerna:
    workdir: "../databases/sortmerna/"
    snakefile: "rules/download_sortmerna_db.smk"
    configfile: "config.yaml"

# rules ########################################################################

# uses databases in sortmerna
rule sortrna:
    input: db = sortmerna("default_db.fasta"),
        reads = expand("{{results}}/qc/cleaned/{{sample}}_{read}.fastq.gz", read=config["reads"])
    output: rrna = "{results}/rrna/{sample}_R1_R2.fastq",
        mrna = "{results}/mrna/{sample}_R1_R2.fastq"
    conda: "../envs/sortmerna.yaml"
    threads: config["threads"]
    params:
        prefix1 = lambda wildcards, output: output.rrna[:-6],
        prefix2 = lambda wildcards, output: output.mrna[:-6],
        workdir = "{results}/database/{sample}/sortmerna"
    shell:
        """
        sortmerna --ref {input.db} --reads {input.reads[0]} --reads {input.reads[1]} --fastx --best 1 --min_lis 10 --blast --paired_in --aligned {params.prefix1} --other {params.prefix2} --workdir {params.workdir} --threads {threads}
        rm -rf {params.workdir}
        workdir: config['workdir']
        """

rule separate_interleaved:
    input: mrna = "{results}/mrna/{sample}_R1_R2.fastq",
        rrna = "{results}/rrna/{sample}_R1_R2.fastq"
    output: mrna_R1 = "{results}/mrna/{sample}_R1.fastq",
        mrna_R2 = "{results}/mrna/{sample}_R2.fastq",
        rrna_R1 = "{results}/rrna/{sample}_R1.fastq",
        rrna_R2 = "{results}/rrna/{sample}_R2.fastq"
    threads: 1
    run:
        separate_fastq(input.mrna, output.mrna_R1, output.mrna_R2)
        separate_fastq(input.rrna, output.rrna_R1, output.rrna_R2)

rule rna_stat:
    input: mrna_R1 = "{results}/mrna/{sample}_R1.fastq",
        rrna_R1 = "{results}/rrna/{sample}_R1.fastq",
    output:
        stat = "{results}/rna_stat_{sample}.txt"
    threads: 1
    params: results = expand("{results}", results=config["results"])
    shell:
        """
            mrna=$(expr $(cat {input.mrna_R1} | wc -l) / 4)
            rrna=$(expr $(cat {input.rrna_R1} | wc -l) / 4)
            all=$(expr $mrna + $rrna)
            mrna_perc=$(expr $mrna \* 100 / $all)
            rrna_perc=$(expr $rrna \* 100 / $all)
            echo mRNA: $mrna \($mrna_perc %\) >> {output}
            echo rRNA: $rrna \($rrna_perc %\) >> {output}
        """
